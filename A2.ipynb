{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf798513",
   "metadata": {
    "id": "cf798513"
   },
   "source": [
    "# CISC/CMPE 452/COGS 400 Assignment 2 - Backpropagation (15 points)  \n",
    "\n",
    "Please put your name and student id here\n",
    "\n",
    "    FirstName LastName, #12345678\n",
    "\n",
    "- The notebook file has clearly marked blocks where you are expected to write code. Do not write or modify any code outside of these blocks.\n",
    "- Make sure to restart and run all the cells from the beginning before submission. Do not clear out the outputs. You will only get credit for code that has been run.\n",
    "- Mark will be deducted based on late policy (-1% of the course total marks per day after due date until the end date after which no assignments will be accepted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95857ed4-e2ac-43fe-8110-9914e3d37848",
   "metadata": {
    "id": "VRLNrFDU3dKp"
   },
   "source": [
    "## [Part 1 (9 points)](#Part-1)  \n",
    "\n",
    "### Build Model1 (7 points)  \n",
    "Use Pytorch to implement a three-layer Neural Network (input layer - hidden layer - output layer) and update the weights with backpropagation  \n",
    "- 1. Implement forward and calculate the output (1 point)  \n",
    "- 2. Calculate errors and loss (3 points)  \n",
    "- 3. Update the weights with backpropagation (1 points)  \n",
    "- 4. Predict function (1 point)  \n",
    "- 5. Activation function (Sigmoid function) (1 point)  \n",
    "\n",
    "### Evaluator Function (1 point)  \n",
    "Implement the evaluator function with Pytorch or Numpy only   \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score\n",
    "\n",
    "### Train and Evaluate Model1 (1 point)  \n",
    "Train Model1 with customized hidden size, learning rate, number of iterations and batch size  \n",
    "Use the predict function to predict the labels with the test dataset  \n",
    "Evaluate the prediction results  \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score\n",
    "\n",
    "## [Part 2 (6 points)](#Part-2)  \n",
    "\n",
    "Use another machine learning framework (**scikit-learn, Tensorflow and Pytorch**) to build MLP\n",
    "e.g. \n",
    "  1. https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "  2. https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "  3. https://pytorch.org/tutorials/beginner/examples_nn/polynomial_nn.html#sphx-glr-beginner-examples-nn-polynomial-nn-py\n",
    "  \n",
    "### Build Model2-1 (2 points)  \n",
    "Implement Model2-1 with the same hidden nodes and optimization function as the model in Part 1  \n",
    "Train and validate model. Use the best model on validation dataset to test on the test dataset  \n",
    "\n",
    "### Train and Evaluate Model2-1 (1 point)\n",
    "Evaluate the prediction results  \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score\n",
    "\n",
    "### Build Model2-2 (2 points)  \n",
    "Add one more hidden layer (2 hidden layers in total) to the model  \n",
    "Describe Model2-2 (number of hidden nodes)  \n",
    "Train and validate model. Use the best model on validation dataset to test on the test dataset  \n",
    "\n",
    "### Train and Evaluate Model2-2 (1 point)\n",
    "Evaluate the prediction results  \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e6a263",
   "metadata": {
    "id": "b7e6a263"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torchmetrics import ConfusionMatrix\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eKE_KANU7_sq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKE_KANU7_sq",
    "outputId": "946cd1ab-22bd-4efa-c734-faab97e6f40d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can go to Edit - Notebook settings to select GPU under the Hardware accelerator\n",
    "# check the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5cbc46",
   "metadata": {
    "id": "9a5cbc46"
   },
   "outputs": [],
   "source": [
    "# build the dataset (train, validation and test)\n",
    "def load_MNIST(n_val=10000, n_sample=1000, sample=False):\n",
    "    n_val = n_val\n",
    "    n_sample = n_sample\n",
    "    train = MNIST(root = '.', train = True, download = True)\n",
    "    test = MNIST(root = '.', train = False, download = True)\n",
    "    \n",
    "    # data preprocessing\n",
    "    x_train, x_test = train.data/255, test.data/255\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "    y_train = torch.nn.functional.one_hot(train.targets)\n",
    "    y_test = torch.nn.functional.one_hot(test.targets)\n",
    "\n",
    "    data_dict = {}\n",
    "    if sample:\n",
    "        data_dict['x_train'] = x_train[:-n_val][:n_sample]\n",
    "        data_dict['y_train'] = y_train[:-n_val][:n_sample]\n",
    "        data_dict['x_val'] = x_train[-n_val:][:n_sample//10]\n",
    "        data_dict['y_val'] = y_train[-n_val:][:n_sample//10]\n",
    "        data_dict['x_test'] = x_test[:n_sample//10]\n",
    "        data_dict['y_test'] = y_test[:n_sample//10]\n",
    "    else:\n",
    "        data_dict['x_train'] = x_train[:-n_val]\n",
    "        data_dict['y_train'] = y_train[:-n_val]\n",
    "        data_dict['x_val'] = x_train[-n_val:]\n",
    "        data_dict['y_val'] = y_train[-n_val:]\n",
    "        data_dict['x_test'] = x_test\n",
    "        data_dict['y_test'] = y_test\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Q5G-vmpD21Bj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Q5G-vmpD21Bj",
    "outputId": "f053f294-9aad-4097-f75e-aaed70dd050e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([50000, 784])\n",
      "Train labels shape: torch.Size([50000, 10])\n",
      "Validation data shape: torch.Size([10000, 784])\n",
      "Validation labels shape: torch.Size([10000, 10])\n",
      "Test data shape: torch.Size([10000, 784])\n",
      "Test labels shape: torch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "# you can start with a small sample dataset by setting sample=True\n",
    "data_dict = load_MNIST(sample=False)\n",
    "print('Train data shape:', data_dict['x_train'].shape)\n",
    "print('Train labels shape:', data_dict['y_train'].shape)\n",
    "print('Validation data shape:', data_dict['x_val'].shape)\n",
    "print('Validation labels shape:', data_dict['y_val'].shape)\n",
    "print('Test data shape:', data_dict['x_test'].shape)\n",
    "print('Test labels shape:', data_dict['y_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa9f016",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "1aa9f016",
    "outputId": "83a4195e-8fb9-4850-8a9a-7c3bbc2bb623"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an example\n",
    "plt.imshow(data_dict['x_train'][0].reshape(28, 28))\n",
    "plt.title(data_dict['y_train'][0].argmax().item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6291c647",
   "metadata": {
    "id": "6291c647"
   },
   "outputs": [],
   "source": [
    "def evaluator(y_test, y_pred):\n",
    "    ####################################################################################################\n",
    "    # enter code here to implement the evaluation metrics including confusion matrix, accuracy, precision and recall\n",
    "    # you can only use Numpy or Pytorch to implement the metrics\n",
    "    test_label = torch.argmax(y_test, dim=1)\n",
    "    \n",
    "    conf_matrix = ConfusionMatrix(num_classes=y_test.shape[1]).to(device)\n",
    "    conf_matrix = conf_matrix(y_pred, test_label).to(device)\n",
    "    \n",
    "    conf_matrix = conf_matrix.cpu().detach().numpy()\n",
    "    \n",
    "    acc = torch.sum(test_label == y_pred).item()/len(test_label)\n",
    "    prec = np.diag(conf_matrix) / np.sum(conf_matrix)\n",
    "    recall = np.diag(conf_matrix) / np.sum(conf_matrix)\n",
    "    fscore = (2*prec*recall)/(prec+recall)\n",
    "    \n",
    "    print(conf_matrix)\n",
    "    print(\"The accuracy of the model is: \", acc)\n",
    "    print(\"The precision of the model is: \", prec)\n",
    "    print(\"The recall of the model is: \", recall)\n",
    "    print(\"The f-measure of the model is: \", fscore)\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a6b06",
   "metadata": {
    "id": "4e4a6b06"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d3fc2d",
   "metadata": {
    "id": "a0d3fc2d"
   },
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    def __init__(self, learning_rate, n_iters, batch_size, hidden_size, device, dtype=torch.float32):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.history = {}\n",
    "        self.history['train_acc'], self.history['val_acc'], self.history['loss'] = [], [], []\n",
    "    \n",
    "    # 5. activation function\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        ####################################################################################################\n",
    "        # enter code here to implement the activation function\n",
    "        if (derivative == True):\n",
    "            return x * (1.0 - x)\n",
    "        return 1/(1 + torch.exp(-x))\n",
    "        \n",
    "        ####################################################################################################\n",
    "\n",
    "    def train(self, x, y, x_val, y_val, verbose=1):\n",
    "        n_train = x.shape[0]\n",
    "        n_val = x_val.shape[0]\n",
    "        input_size = x.shape[1]\n",
    "        num_classes = y.shape[1]\n",
    "        \n",
    "        # weight initialization\n",
    "        self.W1 = torch.randn(input_size, self.hidden_size, dtype=self.dtype, device=self.device) * 0.01\n",
    "        self.W2 = torch.randn(self.hidden_size, num_classes, dtype=self.dtype, device=self.device) * 0.01\n",
    "\n",
    "        # TODO: train the weights with the input data and labels\n",
    "        for i in range(self.n_iters):\n",
    "            loss = 0\n",
    "            data = getBatch(x, y, self.batch_size)\n",
    "            for x_batch, y_batch in data:\n",
    "                # 1. forward\n",
    "                ####################################################################################################\n",
    "                # enter code here to calculate the hidden layer output and output layer output\n",
    "                hidden = self.sigmoid(torch.matmul(x_batch,self.W1), derivative=False)\n",
    "                output = self.sigmoid(torch.matmul(hidden,self.W2), derivative=False)\n",
    "                ####################################################################################################\n",
    "\n",
    "                # 2. error and loss\n",
    "                ####################################################################################################\n",
    "                # enter code here to calculate the output error, MSE loss, delta output and delta hidden\n",
    "                output_error = y_batch - output\n",
    "                loss += (output_error**2).mean()\n",
    "                delta_output = output_error * self.sigmoid(output, derivative=True)\n",
    "                delta_hidden = torch.matmul(delta_output, self.W2.T) * self.sigmoid(hidden, derivative=True)\n",
    "                ####################################################################################################\n",
    "\n",
    "                # 3. backward\n",
    "                ####################################################################################################\n",
    "                # enter code here to calculate delta weights and update the weights\n",
    "                self.W1 += self.learning_rate * torch.matmul(x_batch.T, delta_hidden)\n",
    "                self.W2 += self.learning_rate * torch.matmul(hidden.T, delta_output)\n",
    "                \n",
    "                ####################################################################################################\n",
    "\n",
    "            # calculate the accuracy and save the training history\n",
    "            y_pred = self.predict(x)\n",
    "            train_acc = torch.sum(torch.argmax(y, dim=1) == y_pred) / n_train\n",
    "            self.history['train_acc'].append(train_acc.cpu())\n",
    "            self.history['loss'].append(loss)\n",
    "\n",
    "            y_pred = self.predict(x_val)\n",
    "            val_acc = torch.sum(torch.argmax(y_val, dim=1) == y_pred) / n_val\n",
    "            self.history['val_acc'].append(val_acc.cpu())\n",
    "            if verbose:\n",
    "                print('epoch %d, loss %.4f, train acc %.3f, validation acc %.3f'\n",
    "                  % (i + 1, loss, train_acc, val_acc))\n",
    "    \n",
    "    # 4. predict function \n",
    "    def predict(self, x):\n",
    "        ####################################################################################################\n",
    "        # enter code here to implement the predict function\n",
    "        # TODO: use the trained weights to predict labels and return the predicted labels\n",
    "        # remember to use torch.argmax() to return the true labels\n",
    "        \n",
    "        hidden = self.sigmoid(torch.matmul(x, self.W1))\n",
    "        \n",
    "        output = self.sigmoid(torch.matmul(hidden, self.W2))\n",
    "        \n",
    "        y_pred = torch.argmax(output, dim=1)\n",
    "        ####################################################################################################\n",
    "        return y_pred\n",
    "\n",
    "def getBatch(x, y, batch_size):\n",
    "    n_epoch = x.shape[0] // batch_size\n",
    "    for i in range(n_epoch):\n",
    "        x_batch = x[i * batch_size : (i+1) * batch_size]\n",
    "        y_batch = y[i * batch_size : (i+1) * batch_size]\n",
    "        yield x_batch, y_batch\n",
    "    x_batch = x[(i+1) * batch_size:]\n",
    "    y_batch = y[(i+1) * batch_size:]    \n",
    "    yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e9819c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74e9819c",
    "outputId": "c6b1745f-4e19-4f83-afb7-c22f07062738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss nan, train acc 0.933, validation acc 0.939\n",
      "epoch 2, loss nan, train acc 0.951, validation acc 0.955\n",
      "epoch 3, loss nan, train acc 0.961, validation acc 0.962\n",
      "epoch 4, loss nan, train acc 0.968, validation acc 0.967\n",
      "epoch 5, loss nan, train acc 0.972, validation acc 0.967\n",
      "epoch 6, loss nan, train acc 0.975, validation acc 0.969\n",
      "epoch 7, loss nan, train acc 0.977, validation acc 0.970\n",
      "epoch 8, loss nan, train acc 0.980, validation acc 0.971\n",
      "epoch 9, loss nan, train acc 0.981, validation acc 0.971\n",
      "epoch 10, loss nan, train acc 0.983, validation acc 0.972\n",
      "epoch 11, loss nan, train acc 0.984, validation acc 0.973\n",
      "epoch 12, loss nan, train acc 0.985, validation acc 0.973\n",
      "epoch 13, loss nan, train acc 0.986, validation acc 0.973\n",
      "epoch 14, loss nan, train acc 0.987, validation acc 0.974\n",
      "epoch 15, loss nan, train acc 0.987, validation acc 0.974\n",
      "epoch 16, loss nan, train acc 0.988, validation acc 0.974\n",
      "epoch 17, loss nan, train acc 0.989, validation acc 0.974\n",
      "epoch 18, loss nan, train acc 0.989, validation acc 0.974\n",
      "epoch 19, loss nan, train acc 0.989, validation acc 0.974\n",
      "epoch 20, loss nan, train acc 0.990, validation acc 0.975\n",
      "epoch 21, loss nan, train acc 0.990, validation acc 0.975\n",
      "epoch 22, loss nan, train acc 0.991, validation acc 0.975\n",
      "epoch 23, loss nan, train acc 0.991, validation acc 0.975\n",
      "epoch 24, loss nan, train acc 0.991, validation acc 0.975\n",
      "epoch 25, loss nan, train acc 0.992, validation acc 0.975\n",
      "epoch 26, loss nan, train acc 0.992, validation acc 0.975\n",
      "epoch 27, loss nan, train acc 0.992, validation acc 0.975\n",
      "epoch 28, loss nan, train acc 0.992, validation acc 0.975\n",
      "epoch 29, loss nan, train acc 0.992, validation acc 0.975\n",
      "epoch 30, loss nan, train acc 0.992, validation acc 0.975\n",
      "epoch 31, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 32, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 33, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 34, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 35, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 36, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 37, loss nan, train acc 0.993, validation acc 0.975\n",
      "epoch 38, loss nan, train acc 0.994, validation acc 0.975\n",
      "epoch 39, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 40, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 41, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 42, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 43, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 44, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 45, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 46, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 47, loss nan, train acc 0.994, validation acc 0.976\n",
      "epoch 48, loss nan, train acc 0.994, validation acc 0.975\n",
      "epoch 49, loss nan, train acc 0.994, validation acc 0.975\n",
      "epoch 50, loss nan, train acc 0.994, validation acc 0.975\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to train Model1\n",
    "# TODO: set your desired hidden size, learning rate, number of iterations and batch size\n",
    "# remember to load the dataset to the device (e.g. data_dict['x_train'].to(device))\n",
    "hidden_size = 75\n",
    "learning_rate = 0.1\n",
    "num_iter = 50\n",
    "batch_size = 8\n",
    "\n",
    "model1 = NN(learning_rate, num_iter, batch_size, hidden_size, device)\n",
    "model1.train(data_dict['x_train'].to(device), data_dict['y_train'].to(device), data_dict['x_val'].to(device), data_dict['y_val'].to(device), verbose=1)\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebd0600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "bebd0600",
    "outputId": "4cf59edb-b5bd-417c-913f-78b5a793189f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history['train_acc'], label='train_acc')\n",
    "plt.plot(model1.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "UQciuqY96_6Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQciuqY96_6Z",
    "outputId": "0aff8095-e7a6-4558-f99c-36d2512488f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 966    0    1    0    2    2    3    2    3    1]\n",
      " [   0 1122    3    2    1    2    2    2    1    0]\n",
      " [   4    2 1013    1    1    0    2    6    3    0]\n",
      " [   0    0    6  986    0    5    1    4    7    1]\n",
      " [   1    0    1    0  961    0    5    1    0   13]\n",
      " [   2    0    0   13    2  861    5    1    4    4]\n",
      " [   4    2    1    1    4    3  938    0    5    0]\n",
      " [   1    4   13    2    1    0    0  996    4    7]\n",
      " [   4    0    5    7    6    2    3    2  943    2]\n",
      " [   1    3    0    8    9    2    1    5    6  974]]\n",
      "The accuracy of the model is:  0.976\n",
      "The precision of the model is:  [0.0966 0.1122 0.1013 0.0986 0.0961 0.0861 0.0938 0.0996 0.0943 0.0974]\n",
      "The recall of the model is:  [0.0966 0.1122 0.1013 0.0986 0.0961 0.0861 0.0938 0.0996 0.0943 0.0974]\n",
      "The f-measure of the model is:  [0.0966 0.1122 0.1013 0.0986 0.0961 0.0861 0.0938 0.0996 0.0943 0.0974]\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to evaluate Model1 with test set\n",
    "# TODO: use the trained Model1 to predict the labels of test set and evaluate the results with the evaluator\n",
    "evaluator(data_dict['y_test'].to(device), model1.predict(data_dict['x_test'].to(device)))\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QG_rb7uJ4XDL",
   "metadata": {
    "id": "QG_rb7uJ4XDL"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c845a9",
   "metadata": {},
   "source": [
    "### Model2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13519996",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to implement Model2-1\n",
    "x_train = data_dict['x_train'].numpy()\n",
    "y_train = data_dict['y_train'].numpy()\n",
    "x_val = data_dict['x_val'].numpy()\n",
    "y_val = data_dict['y_val'].numpy()\n",
    "x_test = data_dict['x_test'].numpy()\n",
    "y_test = data_dict['y_test'].numpy()\n",
    "\n",
    "model_2_1 = Sequential()\n",
    "model_2_1.add(Dense(hidden_size, input_dim=x_train.shape[1], activation='sigmoid'))\n",
    "model_2_1.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "model_2_1.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "208a8e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6250/6250 [==============================] - 3s 439us/step - loss: 0.0206 - accuracy: 0.8910\n",
      "Epoch 2/50\n",
      "6250/6250 [==============================] - 3s 434us/step - loss: 0.0096 - accuracy: 0.9451\n",
      "Epoch 3/50\n",
      "6250/6250 [==============================] - 3s 431us/step - loss: 0.0073 - accuracy: 0.9574\n",
      "Epoch 4/50\n",
      "6250/6250 [==============================] - 3s 471us/step - loss: 0.0061 - accuracy: 0.9656\n",
      "Epoch 5/50\n",
      "6250/6250 [==============================] - 3s 432us/step - loss: 0.0052 - accuracy: 0.9717\n",
      "Epoch 6/50\n",
      "6250/6250 [==============================] - 3s 430us/step - loss: 0.0046 - accuracy: 0.9759\n",
      "Epoch 7/50\n",
      "6250/6250 [==============================] - 3s 437us/step - loss: 0.0041 - accuracy: 0.9787\n",
      "Epoch 8/50\n",
      "6250/6250 [==============================] - 3s 433us/step - loss: 0.0037 - accuracy: 0.9816\n",
      "Epoch 9/50\n",
      "6250/6250 [==============================] - 3s 437us/step - loss: 0.0033 - accuracy: 0.9837\n",
      "Epoch 10/50\n",
      "6250/6250 [==============================] - 3s 450us/step - loss: 0.0030 - accuracy: 0.9854\n",
      "Epoch 11/50\n",
      "6250/6250 [==============================] - 3s 431us/step - loss: 0.0028 - accuracy: 0.9861\n",
      "Epoch 12/50\n",
      "6250/6250 [==============================] - 3s 435us/step - loss: 0.0025 - accuracy: 0.9878\n",
      "Epoch 13/50\n",
      "6250/6250 [==============================] - 3s 426us/step - loss: 0.0023 - accuracy: 0.9885\n",
      "Epoch 14/50\n",
      "6250/6250 [==============================] - 3s 426us/step - loss: 0.0021 - accuracy: 0.9899\n",
      "Epoch 15/50\n",
      "6250/6250 [==============================] - 3s 426us/step - loss: 0.0020 - accuracy: 0.9905\n",
      "Epoch 16/50\n",
      "6250/6250 [==============================] - 3s 435us/step - loss: 0.0019 - accuracy: 0.9911\n",
      "Epoch 17/50\n",
      "6250/6250 [==============================] - 3s 426us/step - loss: 0.0017 - accuracy: 0.9915\n",
      "Epoch 18/50\n",
      "6250/6250 [==============================] - 3s 426us/step - loss: 0.0016 - accuracy: 0.9921\n",
      "Epoch 19/50\n",
      "6250/6250 [==============================] - 3s 433us/step - loss: 0.0015 - accuracy: 0.9925\n",
      "Epoch 20/50\n",
      "6250/6250 [==============================] - 3s 429us/step - loss: 0.0014 - accuracy: 0.9929\n",
      "Epoch 21/50\n",
      "6250/6250 [==============================] - 3s 431us/step - loss: 0.0013 - accuracy: 0.9930\n",
      "Epoch 22/50\n",
      "6250/6250 [==============================] - 3s 438us/step - loss: 0.0013 - accuracy: 0.9934\n",
      "Epoch 23/50\n",
      "6250/6250 [==============================] - 3s 436us/step - loss: 0.0012 - accuracy: 0.9938\n",
      "Epoch 24/50\n",
      "6250/6250 [==============================] - 3s 440us/step - loss: 0.0011 - accuracy: 0.9941\n",
      "Epoch 25/50\n",
      "6250/6250 [==============================] - 3s 436us/step - loss: 0.0011 - accuracy: 0.9941\n",
      "Epoch 26/50\n",
      "6250/6250 [==============================] - 3s 432us/step - loss: 9.8515e-04 - accuracy: 0.9945\n",
      "Epoch 27/50\n",
      "6250/6250 [==============================] - 3s 452us/step - loss: 9.6780e-04 - accuracy: 0.9944\n",
      "Epoch 28/50\n",
      "6250/6250 [==============================] - 3s 456us/step - loss: 9.0838e-04 - accuracy: 0.9947\n",
      "Epoch 29/50\n",
      "6250/6250 [==============================] - 3s 440us/step - loss: 8.6806e-04 - accuracy: 0.9949\n",
      "Epoch 30/50\n",
      "6250/6250 [==============================] - 3s 438us/step - loss: 8.3687e-04 - accuracy: 0.9950\n",
      "Epoch 31/50\n",
      "6250/6250 [==============================] - 3s 442us/step - loss: 8.1719e-04 - accuracy: 0.9950\n",
      "Epoch 32/50\n",
      "6250/6250 [==============================] - 3s 440us/step - loss: 7.8757e-04 - accuracy: 0.9951\n",
      "Epoch 33/50\n",
      "6250/6250 [==============================] - 3s 451us/step - loss: 7.3746e-04 - accuracy: 0.9953\n",
      "Epoch 34/50\n",
      "6250/6250 [==============================] - 3s 445us/step - loss: 7.1725e-04 - accuracy: 0.9953\n",
      "Epoch 35/50\n",
      "6250/6250 [==============================] - 3s 442us/step - loss: 7.1377e-04 - accuracy: 0.9954\n",
      "Epoch 36/50\n",
      "6250/6250 [==============================] - 3s 447us/step - loss: 6.7363e-04 - accuracy: 0.9954\n",
      "Epoch 37/50\n",
      "6250/6250 [==============================] - 3s 447us/step - loss: 6.5853e-04 - accuracy: 0.9956\n",
      "Epoch 38/50\n",
      "6250/6250 [==============================] - 3s 439us/step - loss: 6.5153e-04 - accuracy: 0.9955\n",
      "Epoch 39/50\n",
      "6250/6250 [==============================] - 3s 446us/step - loss: 6.3054e-04 - accuracy: 0.9956\n",
      "Epoch 40/50\n",
      "6250/6250 [==============================] - 3s 449us/step - loss: 6.0398e-04 - accuracy: 0.9956\n",
      "Epoch 41/50\n",
      "6250/6250 [==============================] - 3s 440us/step - loss: 5.9805e-04 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "6250/6250 [==============================] - 3s 450us/step - loss: 5.8735e-04 - accuracy: 0.9957\n",
      "Epoch 43/50\n",
      "6250/6250 [==============================] - 3s 449us/step - loss: 5.7870e-04 - accuracy: 0.9957\n",
      "Epoch 44/50\n",
      "6250/6250 [==============================] - 3s 455us/step - loss: 5.7791e-04 - accuracy: 0.9957\n",
      "Epoch 45/50\n",
      "6250/6250 [==============================] - 3s 449us/step - loss: 5.6121e-04 - accuracy: 0.9958\n",
      "Epoch 46/50\n",
      "6250/6250 [==============================] - 3s 436us/step - loss: 5.4990e-04 - accuracy: 0.9957\n",
      "Epoch 47/50\n",
      "6250/6250 [==============================] - 3s 436us/step - loss: 5.3734e-04 - accuracy: 0.9958\n",
      "Epoch 48/50\n",
      "6250/6250 [==============================] - 3s 438us/step - loss: 5.3796e-04 - accuracy: 0.9958\n",
      "Epoch 49/50\n",
      "6250/6250 [==============================] - 3s 456us/step - loss: 5.3678e-04 - accuracy: 0.9958\n",
      "Epoch 50/50\n",
      "6250/6250 [==============================] - 3s 456us/step - loss: 5.3058e-04 - accuracy: 0.9959\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to train Model2-1\n",
    "history = model_2_1.fit(x_train, y_train, epochs=num_iter, batch_size=batch_size)\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f61594f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 966    0    3    1    0    2    6    1    1    0]\n",
      " [   1 1118    5    1    0    1    4    2    3    0]\n",
      " [   5    0 1005    3    2    1    4    7    5    0]\n",
      " [   1    0    5  979    0    9    1    6    5    4]\n",
      " [   1    1    3    0  961    1    5    1    2    7]\n",
      " [   4    0    0    9    1  863    5    2    5    3]\n",
      " [   3    3    0    1    2    2  947    0    0    0]\n",
      " [   0    5   13    3    2    2    0  998    0    5]\n",
      " [   5    0    7    6    3    3    3    3  941    3]\n",
      " [   2    4    0    5   15    6    0    9    4  964]]\n",
      "The accuracy of the model is:  0.9742\n",
      "The precision of the model is:  [0.0966 0.1118 0.1005 0.0979 0.0961 0.0863 0.0947 0.0998 0.0941 0.0964]\n",
      "The recall of the model is:  [0.0966 0.1118 0.1005 0.0979 0.0961 0.0863 0.0947 0.0998 0.0941 0.0964]\n",
      "The f-measure of the model is:  [0.0966 0.1118 0.1005 0.0979 0.0961 0.0863 0.0947 0.0998 0.0941 0.0964]\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to evaluate Model2-1\n",
    "y_pred_2_1 = torch.argmax(torch.from_numpy(model_2_1.predict(x_test)), dim=1)\n",
    "evaluator(torch.from_numpy(y_test).to(device), y_pred_2_1.to(device))\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9243f",
   "metadata": {},
   "source": [
    "### Model2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eaf38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to implement Model2-2\n",
    "hidden_nodes_2 = 50\n",
    "model_2_2 = Sequential()\n",
    "model_2_2.add(Dense(hidden_size, input_dim=x_train.shape[1], activation='sigmoid'))\n",
    "model_2_2.add(Dense(hidden_nodes_2, activation='sigmoid'))\n",
    "model_2_2.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "model_2_2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "090300ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6250/6250 [==============================] - 3s 446us/step - loss: 0.0235 - accuracy: 0.8583\n",
      "Epoch 2/50\n",
      "6250/6250 [==============================] - 3s 458us/step - loss: 0.0084 - accuracy: 0.9487\n",
      "Epoch 3/50\n",
      "6250/6250 [==============================] - 3s 470us/step - loss: 0.0061 - accuracy: 0.9627\n",
      "Epoch 4/50\n",
      "6250/6250 [==============================] - 3s 485us/step - loss: 0.0049 - accuracy: 0.9715\n",
      "Epoch 5/50\n",
      "6250/6250 [==============================] - 3s 457us/step - loss: 0.0040 - accuracy: 0.9775\n",
      "Epoch 6/50\n",
      "6250/6250 [==============================] - 3s 459us/step - loss: 0.0034 - accuracy: 0.9806\n",
      "Epoch 7/50\n",
      "6250/6250 [==============================] - 3s 467us/step - loss: 0.0029 - accuracy: 0.9836\n",
      "Epoch 8/50\n",
      "6250/6250 [==============================] - 3s 459us/step - loss: 0.0025 - accuracy: 0.9861\n",
      "Epoch 9/50\n",
      "6250/6250 [==============================] - 3s 473us/step - loss: 0.0022 - accuracy: 0.9882\n",
      "Epoch 10/50\n",
      "6250/6250 [==============================] - 3s 467us/step - loss: 0.0019 - accuracy: 0.9898\n",
      "Epoch 11/50\n",
      "6250/6250 [==============================] - 3s 457us/step - loss: 0.0018 - accuracy: 0.9904\n",
      "Epoch 12/50\n",
      "6250/6250 [==============================] - 3s 459us/step - loss: 0.0016 - accuracy: 0.9913\n",
      "Epoch 13/50\n",
      "6250/6250 [==============================] - 3s 483us/step - loss: 0.0015 - accuracy: 0.9917\n",
      "Epoch 14/50\n",
      "6250/6250 [==============================] - 3s 478us/step - loss: 0.0013 - accuracy: 0.9932\n",
      "Epoch 15/50\n",
      "6250/6250 [==============================] - 3s 468us/step - loss: 0.0012 - accuracy: 0.9935\n",
      "Epoch 16/50\n",
      "6250/6250 [==============================] - 3s 488us/step - loss: 0.0011 - accuracy: 0.9943\n",
      "Epoch 17/50\n",
      "6250/6250 [==============================] - 3s 484us/step - loss: 0.0010 - accuracy: 0.9945\n",
      "Epoch 18/50\n",
      "6250/6250 [==============================] - 3s 475us/step - loss: 9.7706e-04 - accuracy: 0.9947\n",
      "Epoch 19/50\n",
      "6250/6250 [==============================] - 3s 464us/step - loss: 9.0384e-04 - accuracy: 0.9951\n",
      "Epoch 20/50\n",
      "6250/6250 [==============================] - 3s 472us/step - loss: 8.3154e-04 - accuracy: 0.9954\n",
      "Epoch 21/50\n",
      "6250/6250 [==============================] - 3s 466us/step - loss: 8.0389e-04 - accuracy: 0.9954\n",
      "Epoch 22/50\n",
      "6250/6250 [==============================] - 3s 472us/step - loss: 7.5115e-04 - accuracy: 0.9958\n",
      "Epoch 23/50\n",
      "6250/6250 [==============================] - 3s 478us/step - loss: 7.2756e-04 - accuracy: 0.9958\n",
      "Epoch 24/50\n",
      "6250/6250 [==============================] - 3s 466us/step - loss: 7.1082e-04 - accuracy: 0.9958\n",
      "Epoch 25/50\n",
      "6250/6250 [==============================] - 3s 458us/step - loss: 6.6707e-04 - accuracy: 0.9963\n",
      "Epoch 26/50\n",
      "6250/6250 [==============================] - 3s 461us/step - loss: 6.3369e-04 - accuracy: 0.9963\n",
      "Epoch 27/50\n",
      "6250/6250 [==============================] - 3s 465us/step - loss: 6.0752e-04 - accuracy: 0.9965\n",
      "Epoch 28/50\n",
      "6250/6250 [==============================] - 3s 464us/step - loss: 6.1018e-04 - accuracy: 0.9967\n",
      "Epoch 29/50\n",
      "6250/6250 [==============================] - 3s 467us/step - loss: 5.7493e-04 - accuracy: 0.9965\n",
      "Epoch 30/50\n",
      "6250/6250 [==============================] - 3s 464us/step - loss: 5.4864e-04 - accuracy: 0.9967\n",
      "Epoch 31/50\n",
      "6250/6250 [==============================] - 3s 467us/step - loss: 5.3729e-04 - accuracy: 0.9970\n",
      "Epoch 32/50\n",
      "6250/6250 [==============================] - 3s 464us/step - loss: 5.4635e-04 - accuracy: 0.9969\n",
      "Epoch 33/50\n",
      "6250/6250 [==============================] - 3s 463us/step - loss: 5.1240e-04 - accuracy: 0.9971\n",
      "Epoch 34/50\n",
      "6250/6250 [==============================] - 3s 467us/step - loss: 4.9651e-04 - accuracy: 0.9972\n",
      "Epoch 35/50\n",
      "6250/6250 [==============================] - 3s 469us/step - loss: 5.1649e-04 - accuracy: 0.9970\n",
      "Epoch 36/50\n",
      "6250/6250 [==============================] - 3s 471us/step - loss: 5.1391e-04 - accuracy: 0.9969\n",
      "Epoch 37/50\n",
      "6250/6250 [==============================] - 3s 476us/step - loss: 4.8541e-04 - accuracy: 0.9972\n",
      "Epoch 38/50\n",
      "6250/6250 [==============================] - 3s 483us/step - loss: 4.6871e-04 - accuracy: 0.9973\n",
      "Epoch 39/50\n",
      "6250/6250 [==============================] - 3s 478us/step - loss: 4.5314e-04 - accuracy: 0.9974\n",
      "Epoch 40/50\n",
      "6250/6250 [==============================] - 3s 472us/step - loss: 4.5139e-04 - accuracy: 0.9973\n",
      "Epoch 41/50\n",
      "6250/6250 [==============================] - 3s 458us/step - loss: 4.3053e-04 - accuracy: 0.9973\n",
      "Epoch 42/50\n",
      "6250/6250 [==============================] - 3s 455us/step - loss: 4.2969e-04 - accuracy: 0.9974\n",
      "Epoch 43/50\n",
      "6250/6250 [==============================] - 3s 455us/step - loss: 4.3757e-04 - accuracy: 0.9975\n",
      "Epoch 44/50\n",
      "6250/6250 [==============================] - 3s 460us/step - loss: 4.0665e-04 - accuracy: 0.9976\n",
      "Epoch 45/50\n",
      "6250/6250 [==============================] - 3s 468us/step - loss: 4.0914e-04 - accuracy: 0.9976\n",
      "Epoch 46/50\n",
      "6250/6250 [==============================] - 3s 469us/step - loss: 3.9486e-04 - accuracy: 0.9977\n",
      "Epoch 47/50\n",
      "6250/6250 [==============================] - 3s 467us/step - loss: 3.6193e-04 - accuracy: 0.9979\n",
      "Epoch 48/50\n",
      "6250/6250 [==============================] - 3s 463us/step - loss: 3.8823e-04 - accuracy: 0.9977\n",
      "Epoch 49/50\n",
      "6250/6250 [==============================] - 3s 475us/step - loss: 3.6664e-04 - accuracy: 0.9978\n",
      "Epoch 50/50\n",
      "6250/6250 [==============================] - 3s 463us/step - loss: 3.6841e-04 - accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to train Model2-2\n",
    "history = model_2_2.fit(x_train, y_train, epochs=num_iter, batch_size=batch_size)\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca87daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 967    0    1    3    1    5    1    1    1    0]\n",
      " [   0 1127    0    1    0    1    4    1    1    0]\n",
      " [   5    6  991   10    3    0    3    9    5    0]\n",
      " [   0    0    2  989    0    9    0    7    3    0]\n",
      " [   2    0    2    1  959    0    6    2    1    9]\n",
      " [   2    0    0   13    1  863    7    0    4    2]\n",
      " [   5    2    1    1    4    3  940    0    2    0]\n",
      " [   2    1    7    9    1    0    0 1003    0    5]\n",
      " [   5    1    4   10    9    9    2    3  930    1]\n",
      " [   3    4    0   11   18    6    0    5    4  958]]\n",
      "The accuracy of the model is:  0.9727\n",
      "The precision of the model is:  [0.0967 0.1127 0.0991 0.0989 0.0959 0.0863 0.094  0.1003 0.093  0.0958]\n",
      "The recall of the model is:  [0.0967 0.1127 0.0991 0.0989 0.0959 0.0863 0.094  0.1003 0.093  0.0958]\n",
      "The f-measure of the model is:  [0.0967 0.1127 0.0991 0.0989 0.0959 0.0863 0.094  0.1003 0.093  0.0958]\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to evaluate Model2-2\n",
    "y_pred_2_2 = torch.argmax(torch.from_numpy(model_2_2.predict(x_test)), dim=1)\n",
    "evaluator(torch.from_numpy(y_test).to(device), y_pred_2_2.to(device))\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe3906-ba99-48d1-b07c-30dc78e3bd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "A2_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
